# SmolVLM + llama.cpp ì•ˆë“œë¡œì´ë“œ í†µí•© ë¦¬ì„œì¹˜

> ì—°êµ¬ ë‚ ì§œ: 2025-10-23
> ëª©ì : SmolVLM-500M-Instruct ëª¨ë¸ì„ llama.cpp ì„œë²„ë¡œ ì•ˆë“œë¡œì´ë“œ ì•±ì— í†µí•©í•˜ëŠ” ë°©ë²• ì¡°ì‚¬

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [SmolVLM ëª¨ë¸ ì •ë³´](#smolvlm-ëª¨ë¸-ì •ë³´)
3. [ì•ˆë“œë¡œì´ë“œ ì‹¤í–‰ ê°€ëŠ¥ì„±](#ì•ˆë“œë¡œì´ë“œ-ì‹¤í–‰-ê°€ëŠ¥ì„±)
4. [í†µí•© ë°©ë²•](#í†µí•©-ë°©ë²•)
5. [ë ˆí¼ëŸ°ìŠ¤ í”„ë¡œì íŠ¸](#ë ˆí¼ëŸ°ìŠ¤-í”„ë¡œì íŠ¸)
6. [êµ¬í˜„ ê°€ì´ë“œ](#êµ¬í˜„-ê°€ì´ë“œ)
7. [ì„±ëŠ¥ ë° ìš”êµ¬ì‚¬í•­](#ì„±ëŠ¥-ë°-ìš”êµ¬ì‚¬í•­)
8. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## ê°œìš”

### SmolVLMì´ë€?

- **ëª¨ë¸ í¬ê¸°**: 2B íŒŒë¼ë¯¸í„° (500M ë²„ì „ë„ ì¡´ì¬)
- **íƒ€ì…**: Vision Language Model (VLM)
- **íŠ¹ì§•**: ëª¨ë°”ì¼ ë° ì—£ì§€ ë””ë°”ì´ìŠ¤ì— ìµœì í™”ëœ ê²½ëŸ‰ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸
- **ë¼ì´ì„ ìŠ¤**: Apache 2.0
- **ëª¨ë¸ ì €ì¥ì†Œ**: [ggml-org/SmolVLM-500M-Instruct-GGUF](https://huggingface.co/ggml-org/SmolVLM-500M-Instruct-GGUF)

### ì£¼ìš” ì¥ì 

- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: VLM ì¤‘ ê°€ì¥ ë‚®ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- **ë¹ ë¥¸ ì†ë„**:
  - Prefill ì†ë„: 3-4.5ë°° ë¹ ë¦„
  - Generation ì†ë„: ìµœëŒ€ 16ë°° ë¹ ë¦„ (Qwen2-VL ëŒ€ë¹„)
- **íš¨ìœ¨ì ì¸ ì¸ì½”ë”©**: 384x384 ì´ë¯¸ì§€ë¥¼ 81 í† í°ìœ¼ë¡œ ì¸ì½”ë”©
- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ì›¹ìº  ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ê°€ëŠ¥

---

## ì•ˆë“œë¡œì´ë“œ ì‹¤í–‰ ê°€ëŠ¥ì„±

### âœ… ê²°ë¡ : ì™„ì „íˆ ê°€ëŠ¥

llama.cppëŠ” ì•ˆë“œë¡œì´ë“œë¥¼ ê³µì‹ ì§€ì›í•˜ë©°, SmolVLM-500Mì€ ëª¨ë°”ì¼ í™˜ê²½ì— ë§¤ìš° ì í•©í•©ë‹ˆë‹¤.

### ì§€ì› í”Œë«í¼

- **ì•„í‚¤í…ì²˜**: arm64-v8a, x86_64
- **ìµœì†Œ Android API**: 28 (Android 9.0)
- **GPU ê°€ì†**: Qualcomm Adreno (OpenCL) - b5028 ì´ì „ ë²„ì „

### ì‹¤ì œ ì‚¬ë¡€

- SmolVLM2 ì•ˆë“œë¡œì´ë“œ ì•± êµ¬í˜„ ì‚¬ë¡€ ì¡´ì¬
- CPU-only ì¶”ë¡ ìœ¼ë¡œë„ ìš°ìˆ˜í•œ ì„±ëŠ¥ ë³´ê³ 
- ì‹¤ì‹œê°„ ë¹„ì „ ì‘ì—… ê°€ëŠ¥

---

## í†µí•© ë°©ë²•

### ë°©ë²• ë¹„êµ

| ë°©ë²• | ë‚œì´ë„ | ì„±ëŠ¥ | ìœ ì§€ë³´ìˆ˜ | ì¶”ì²œë„ |
|------|--------|------|----------|--------|
| **Termux** | â­ | ì¤‘ | ë‚®ìŒ | í”„ë¡œí† íƒ€ì…ìš© |
| **React Native (llama.rn)** | â­â­ | ì¤‘ìƒ | ì¤‘ | í¬ë¡œìŠ¤í”Œë«í¼ |
| **Kotlin + JNA** | â­â­â­ | ìƒ | ì¤‘ìƒ | **ê¸°ì¡´ ì•± í†µí•© ì¶”ì²œ** |
| **Kotlin + JNI** | â­â­â­â­ | ìµœìƒ | ë†’ìŒ | ê³ ì„±ëŠ¥ í•„ìš”ì‹œ |

### ê¸°ì¡´ Kotlin ì•± í†µí•© ì‹œ ê¶Œì¥: JNA ë°©ì‹

**ì¥ì :**
- JNIë³´ë‹¤ ê°„ë‹¨í•œ ë°”ì¸ë”©
- ë„¤ì´í‹°ë¸Œ ì½”ë“œ ì‘ì„± ë¶ˆí•„ìš”
- ìœ ì§€ë³´ìˆ˜ ìš©ì´

**ë‹¨ì :**
- JNIë³´ë‹¤ ì•½ê°„ ëŠë¦¼ (ì‹¤ìš©ì ìœ¼ë¡œëŠ” ë¬´ì‹œ ê°€ëŠ¥)

---

## ë ˆí¼ëŸ°ìŠ¤ í”„ë¡œì íŠ¸

### 1. kotlinllamacpp â­ ìµœìš°ì„  ì¶”ì²œ

- **URL**: https://github.com/ljcamargo/kotlinllamacpp
- **íŠ¹ì§•**:
  - Kotlin ë„¤ì´í‹°ë¸Œ ë°”ì¸ë”©
  - 16kb pagination ì§€ì› (ìµœì‹  Android)
  - ì‰¬ìš´ ì‚¬ìš©ë²•
- **ì‚¬ìš© ì˜ˆì‹œ**:
  ```kotlin
  implementation("io.github.ljcamargo:kotlinllamacpp:1.0.0")
  ```

### 2. llama-cpp-kt (JNA ê¸°ë°˜)

- **URL**: https://github.com/hurui200320/llama-cpp-kt
- **íŠ¹ì§•**:
  - JNA ì‚¬ìš©ìœ¼ë¡œ ê°„í¸í•œ í†µí•©
  - `-DBUILD_SHARED_LIBS=ON` í”Œë˜ê·¸ë¡œ ë¹Œë“œ í•„ìš”

### 3. llama-jni (JNI ê¸°ë°˜)

- **URL**: https://github.com/shixiangcap/llama-jni
- **íŠ¹ì§•**:
  - ì „í†µì ì¸ JNI ë°©ì‹
  - ìµœê³  ì„±ëŠ¥

### 4. llama.cpp-android-tutorial

- **URL**: https://github.com/JackZeng0208/llama.cpp-android-tutorial
- **íŠ¹ì§•**:
  - GPU ê°€ì† ê°€ì´ë“œ
  - Adreno OpenCL ì§€ì›

### 5. llama.rn (React Native)

- **URL**: https://github.com/mybigday/llama.rn
- **íŠ¹ì§•**:
  - í¬ë¡œìŠ¤í”Œë«í¼
  - Vision ëª¨ë¸ ì§€ì›
  - ì„¤ì¹˜ ê°„í¸: `npm install llama.rn`

### 6. ì‹¤ì‹œê°„ ì›¹ìº  ì˜ˆì œ

- **URL**: https://github.com/ngxson/smolvlm-realtime-webcam
- **íŠ¹ì§•**:
  - SmolVLM ì‹¤ì‹œê°„ ê°ì²´ íƒì§€
  - HTML + llama-server êµ¬ì¡°

---

## êµ¬í˜„ ê°€ì´ë“œ

### 1ë‹¨ê³„: llama.cpp ë¹Œë“œ

```bash
# Android NDK ì„¤ì •
export ANDROID_NDK=/path/to/android-ndk

# llama.cpp í´ë¡  (b5028 ì´ì „ ë²„ì „ ê¶Œì¥)
git clone https://github.com/ggml-org/llama.cpp
cd llama.cpp
git checkout <commit-before-b5028>

# Androidìš© ë¹Œë“œ (arm64-v8a)
cmake -B build-android \
  -DCMAKE_TOOLCHAIN_FILE=$ANDROID_NDK/build/cmake/android.toolchain.cmake \
  -DANDROID_ABI=arm64-v8a \
  -DANDROID_PLATFORM=android-28 \
  -DGGML_OPENMP=OFF \
  -DGGML_LLAMAFILE=OFF \
  -DBUILD_SHARED_LIBS=ON

# ë¹Œë“œ ì‹¤í–‰
cmake --build build-android --config Release -j8

# ê²°ê³¼ë¬¼: build-android/libllama.so
```

### 2ë‹¨ê³„: Android í”„ë¡œì íŠ¸ êµ¬ì¡°

```
your-app/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/main/
â”‚   â”‚   â”œâ”€â”€ jniLibs/
â”‚   â”‚   â”‚   â””â”€â”€ arm64-v8a/
â”‚   â”‚   â”‚       â””â”€â”€ libllama.so         # ì—¬ê¸°ì— ë³µì‚¬
â”‚   â”‚   â”œâ”€â”€ assets/
â”‚   â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚   â”‚       â””â”€â”€ smolvlm-500m-q4.gguf
â”‚   â”‚   â””â”€â”€ java/com/yourapp/
â”‚   â”‚       â”œâ”€â”€ llama/
â”‚   â”‚       â”‚   â”œâ”€â”€ LlamaWrapper.kt
â”‚   â”‚       â”‚   â””â”€â”€ LlamaViewModel.kt
â”‚   â”‚       â””â”€â”€ MainActivity.kt
â”‚   â””â”€â”€ build.gradle.kts
```

### 3ë‹¨ê³„: build.gradle.kts ì„¤ì •

```kotlin
android {
    defaultConfig {
        ndk {
            abiFilters += listOf("arm64-v8a")
        }
    }

    // 16kb pagination ì§€ì› (Android 15+)
    packagingOptions {
        jniLibs {
            useLegacyPackaging = true
        }
    }
}

dependencies {
    // JNA ë°©ì‹ ì‚¬ìš©ì‹œ
    implementation("net.java.dev.jna:5.13.0@aar")

    // ë˜ëŠ” kotlinllamacpp ì‚¬ìš©
    // implementation("io.github.ljcamargo:kotlinllamacpp:1.0.0")
}
```

### 4ë‹¨ê³„: Kotlin ë°”ì¸ë”© (JNA ì˜ˆì‹œ)

```kotlin
// LlamaWrapper.kt
import com.sun.jna.Library
import com.sun.jna.Native
import com.sun.jna.Pointer

interface LlamaLib : Library {
    fun llama_model_load(path: String, params: Pointer): Pointer
    fun llama_context_new(model: Pointer, params: Pointer): Pointer
    fun llama_generate(context: Pointer, prompt: String): String
    fun llama_free(context: Pointer)

    companion object {
        val INSTANCE: LlamaLib by lazy {
            Native.load("llama", LlamaLib::class.java)
        }
    }
}

class LlamaManager(private val context: Context) {
    private var modelContext: Pointer? = null

    fun loadModel(modelPath: String) {
        val params = createDefaultParams()
        val model = LlamaLib.INSTANCE.llama_model_load(modelPath, params)
        modelContext = LlamaLib.INSTANCE.llama_context_new(model, params)
    }

    fun generate(prompt: String): String {
        return modelContext?.let {
            LlamaLib.INSTANCE.llama_generate(it, prompt)
        } ?: ""
    }

    fun cleanup() {
        modelContext?.let { LlamaLib.INSTANCE.llama_free(it) }
    }
}
```

### 5ë‹¨ê³„: Vision ëª¨ë¸ ì‚¬ìš©

```kotlin
// ì´ë¯¸ì§€ ë¡œë”©
fun loadImageAsBytes(uri: Uri): ByteArray {
    return context.contentResolver.openInputStream(uri)?.use {
        it.readBytes()
    } ?: byteArrayOf()
}

// SmolVLM ì¶”ë¡ 
fun analyzeImage(imageUri: Uri, prompt: String): String {
    val imageBytes = loadImageAsBytes(imageUri)
    return llamaManager.generateWithImage(
        prompt = prompt,
        imageData = imageBytes
    )
}
```

### 6ë‹¨ê³„: ëª¨ë¸ íŒŒì¼ ê´€ë¦¬

```kotlin
// ViewModelì—ì„œ
class LlamaViewModel(application: Application) : AndroidViewModel(application) {
    private val modelPath = File(application.filesDir, "models/smolvlm-500m-q4.gguf")

    init {
        copyModelFromAssets()
    }

    private fun copyModelFromAssets() {
        if (!modelPath.exists()) {
            modelPath.parentFile?.mkdirs()
            application.assets.open("models/smolvlm-500m-q4.gguf").use { input ->
                FileOutputStream(modelPath).use { output ->
                    input.copyTo(output)
                }
            }
        }
    }
}
```

### 7ë‹¨ê³„: ê¶Œí•œ ì„¤ì • (AndroidManifest.xml)

```xml
<manifest>
    <uses-permission android:name="android.permission.CAMERA" />
    <uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE" />
    <uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" />

    <application>
        <!-- extractNativeLibs for 16kb pagination -->
        android:extractNativeLibs="false"
        ...
    </application>
</manifest>
```

---

## ì„±ëŠ¥ ë° ìš”êµ¬ì‚¬í•­

### í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­

| í•­ëª© | ìµœì†Œ | ê¶Œì¥ |
|------|------|------|
| **RAM** | 4GB | 6GB+ |
| **ì €ì¥ê³µê°„** | 2GB | 4GB+ |
| **í”„ë¡œì„¸ì„œ** | 64-bit ARM | Snapdragon 8 Gen 1+ |
| **Android ë²„ì „** | 9.0 (API 28) | 12.0+ (API 31) |

### ëª¨ë¸ í¬ê¸°ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

| ëª¨ë¸ | í¬ê¸° | RAM ì‚¬ìš©ëŸ‰ | ì¶”ë¡  ì†ë„ |
|------|------|------------|-----------|
| SmolVLM-500M-Q4_K_M | ~300MB | ~1.5GB | ë¹ ë¦„ |
| SmolVLM-500M-Q5_K_M | ~400MB | ~2GB | ë³´í†µ |
| SmolVLM-500M-Q6_K | ~500MB | ~2.5GB | ëŠë¦¼ |

### ì„±ëŠ¥ ìµœì í™” íŒ

```kotlin
// Context í¬ê¸° ì¡°ì ˆ
val params = LlamaParams().apply {
    n_ctx = 2048  // 4096ì€ ë©”ëª¨ë¦¬ ë¶€ì¡± ê°€ëŠ¥
    n_threads = 4 // CPU ì½”ì–´ ìˆ˜ì— ë§ê²Œ
    use_mlock = true
    use_mmap = true
}

// ë°°ì¹˜ í¬ê¸° ì¡°ì ˆ
val batchSize = 512 // ê¸°ë³¸ê°’, ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ 256ìœ¼ë¡œ
```

### ì˜ˆìƒ ì„±ëŠ¥

- **ì´ë¯¸ì§€ ì¸ì½”ë”©**: ~100-200ms (CPU)
- **í…ìŠ¤íŠ¸ ìƒì„±**: ~50-100 tokens/sec (CPU)
- **ì „ì²´ ì¶”ë¡ **: ~1-2ì´ˆ (ê°„ë‹¨í•œ ì§ˆë¬¸)

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì‹¤íŒ¨

**ì—ëŸ¬:**
```
java.lang.UnsatisfiedLinkError: dlopen failed: library "libllama.so" not found
```

**í•´ê²°:**
```bash
# adbë¡œ í™•ì¸
adb shell run-as com.yourapp ls -la /data/data/com.yourapp/lib/

# build.gradleì— ì¶”ê°€
android {
    packagingOptions {
        jniLibs.useLegacyPackaging = true
    }
}
```

### 2. Segmentation Fault

**ì›ì¸:** llama.cpp ìµœì‹  ë²„ì „ (b5028 ì´í›„)

**í•´ê²°:**
```bash
# b5028 ì´ì „ ë²„ì „ìœ¼ë¡œ ì²´í¬ì•„ì›ƒ
cd llama.cpp
git checkout <commit-before-b5028>
```

### 3. Out of Memory

**í•´ê²°:**
```kotlin
// Context í¬ê¸° ì¤„ì´ê¸°
n_ctx = 2048  // 4096ì—ì„œ ì¤„ì„

// ë” ì‘ì€ quantization ëª¨ë¸ ì‚¬ìš©
// Q6 -> Q5 -> Q4
```

### 4. 16kb Pagination ì—ëŸ¬ (Android 15+)

**ì—ëŸ¬:**
```
CANNOT LINK EXECUTABLE: requires 16kb page size
```

**í•´ê²°:**
```kotlin
// build.gradle
android {
    packagingOptions {
        jniLibs {
            useLegacyPackaging = true
        }
    }
}

// AndroidManifest.xml
<application android:extractNativeLibs="false">
```

### 5. GPU ê°€ì† ì‹¤íŒ¨ (Adreno)

**í•´ê²°:**
```bash
# OpenCL ì§€ì› ë¹Œë“œ
cmake -B build-android \
  -DGGML_OPENCL=ON \
  -DGGML_OPENCL_USE_ADRENO=ON \
  ...

# b5028 ì´ì „ ë²„ì „ í•„ìˆ˜!
```

---

## ë¹ ë¥¸ ì‹œì‘ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Android NDK ì„¤ì¹˜
- [ ] llama.cpp ë¹Œë“œ (b5028 ì´ì „ ë²„ì „)
- [ ] libllama.soë¥¼ jniLibs/arm64-v8a/ì— ë³µì‚¬
- [ ] build.gradle ì„¤ì • (ndk, packagingOptions)
- [ ] JNA ë˜ëŠ” kotlinllamacpp dependency ì¶”ê°€
- [ ] GGUF ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (SmolVLM-500M-Q4 ê¶Œì¥)
- [ ] assets/models/ì— ëª¨ë¸ ë°°ì¹˜
- [ ] ê¶Œí•œ ì„¤ì • (CAMERA, STORAGE)
- [ ] Kotlin ë˜í¼ ì‘ì„±
- [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰

---

## ì¶”ê°€ ë¦¬ì†ŒìŠ¤

### ê³µì‹ ë¬¸ì„œ

- [llama.cpp GitHub](https://github.com/ggml-org/llama.cpp)
- [llama.cpp Android Docs](https://github.com/ggml-org/llama.cpp/blob/master/docs/android.md)
- [SmolVLM Hugging Face](https://huggingface.co/blog/smolvlm)

### íŠœí† ë¦¬ì–¼ & ë¸”ë¡œê·¸

- [How to compile LLM on Android using LLama.cpp (Medium)](https://medium.com/@mmonteirojs/how-to-compile-any-llm-on-android-using-llama-cpp-46885569768d)
- [Run Gemma and VLMs on mobile (Medium)](https://farmaker47.medium.com/run-gemma-and-vlms-on-mobile-with-llama-cpp-dbb6e1b19a93)
- [LLM Inference on Edge (Hugging Face)](https://huggingface.co/blog/llm-inference-on-edge)

### ì»¤ë®¤ë‹ˆí‹°

- [llama.cpp Discussions](https://github.com/ggml-org/llama.cpp/discussions)
- [Building llama.cpp for Android Discussion](https://github.com/ggml-org/llama.cpp/discussions/4960)

---

## ê²°ë¡ 

SmolVLM-500M + llama.cppë¥¼ ê¸°ì¡´ Kotlin Android ì•±ì— í†µí•©í•˜ëŠ” ê²ƒì€ **ì™„ì „íˆ ê°€ëŠ¥**í•˜ë©°, ë‹¤ìŒ ë°©ë²•ì„ ì¶”ì²œí•©ë‹ˆë‹¤:

1. **kotlinllamacpp ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©** (ê°€ì¥ ê°„ë‹¨)
2. ë˜ëŠ” **llama-cpp-kt (JNA ê¸°ë°˜)** ì‚¬ìš©
3. ëª¨ë¸ì€ **SmolVLM-500M-Q4_K_M** ì‚¬ìš© (ì„±ëŠ¥/í¬ê¸° ë°¸ëŸ°ìŠ¤)

í”„ë¡œí† íƒ€ì…ì„ ë¹ ë¥´ê²Œ ë§Œë“¤ê³  ì‹¶ë‹¤ë©´ ê¸°ì¡´ í”„ë¡œì íŠ¸ë¥¼ í¬í¬í•´ì„œ í•„ìš”í•œ ë¶€ë¶„ë§Œ ë³µì‚¬í•˜ëŠ” ê²ƒì´ ê°€ì¥ íš¨ìœ¨ì ì…ë‹ˆë‹¤.

---

**ì—°êµ¬ ì™„ë£Œì¼**: 2025-10-23
**ë‹¤ìŒ ë‹¨ê³„**: ì‹¤ì œ êµ¬í˜„ ë° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
