# Quick Start - SmolVLM Training (CORRECTED)

## TL;DR

Your training code has been fixed based on **proven tutorials**. The key was using the **chat template approach** instead of manual token manipulation.

---

## What Was Fixed ðŸ”§

### The Problem
Original code tried to manually concatenate tokens - this is NOT how VLM processors work!

### The Solution
Use `processor.apply_chat_template()` - the standard way ALL VLM tutorials use.

---

## Test It Now! ðŸ§ª

```bash
cd fortuna_android/fine-tuning

# 1. Run validation tests
python test_training.py

# Expected output: All tests PASS
# Critical check: "Target tokens: XX (not 0!)"
```

---

## If Tests Pass, Train! ðŸš€

### Small Test (5-10 min):
```bash
python finetune_smolvlm_v2.py \
    --dataset_dir ./dataset \
    --output_dir ./models/test_run \
    --num_epochs 1 \
    --batch_size 2 \
    --max_steps 10 \
    --bf16
```

**Watch for**: Loss should DECREASE (e.g., 3.5 â†’ 2.1 â†’ 1.4)

### Full Training (4-8 hours on GPU):
```bash
python finetune_smolvlm_v2.py \
    --dataset_dir ./dataset \
    --output_dir ./models/smolvlm-element \
    --num_epochs 3 \
    --batch_size 4 \
    --gradient_accumulation_steps 4 \
    --learning_rate 2e-4 \
    --bf16 \
    --wandb_project smolvlm-android-aligned
```

---

## Key Changes Made

### 1. Dataset (`__getitem__`):
```python
# Returns raw messages + image
return {
    "image": image,
    "messages": [
        {"role": "user", "content": [...]},
        {"role": "assistant", "content": [...]}
    ]
}
```

### 2. Collator:
```python
# Uses chat template!
texts = [processor.apply_chat_template(ex["messages"], ...) for ex in examples]
batch = processor(images=images, text=texts, ...)
labels = batch["input_ids"].clone()
labels[labels == pad_token_id] = -100
```

### 3. Trainer:
```python
# Passes processor to collator
data_collator=VisionLanguageDataCollator(processor=processor)
```

---

## Why This Works âœ…

- âœ… Based on **Phil Schmid's tutorial** (proven approach)
- âœ… Uses **chat templates** (standard for VLMs)
- âœ… Processor handles **all complexity**
- âœ… **Simple and clean** (not manual token manipulation)

---

## Files You Need

1. âœ… `finetune_smolvlm_v2.py` - Main training script (FIXED)
2. âœ… `test_training.py` - Validation script (UPDATED)
3. âœ… `dataset/` - Your data (ready, 900 train + 100 val)
4. âœ… `requirements.txt` - Dependencies

---

## Expected Results

### Test Script:
```
âœ… PASS: Dataset loading
âœ… PASS: Package imports
âœ… PASS: Processor loading
âœ… PASS: Dataset class works
âœ… PASS: Data collator works
   Target tokens: 48 (6.2%)  â† This MUST be > 0!

ðŸŽ‰ All tests passed! Ready to train.
```

### Training:
```
Epoch 1: loss=2.456 â†’ 1.823 â†’ 1.234 â†’ 0.894  (decreasing âœ…)
Epoch 2: loss=0.745 â†’ 0.623 â†’ 0.512          (still decreasing âœ…)
Epoch 3: loss=0.423 â†’ 0.367 â†’ 0.312          (converging âœ…)

Final accuracy: 85%+ on validation set
```

---

## Troubleshooting

### Q: Tests fail with "No module named 'torch'"
**A**: Install dependencies
```bash
pip install -r requirements.txt
```

### Q: "Target tokens: 0" in test output
**A**: This is BAD - means labels are broken. But with the fix, this shouldn't happen!

### Q: Loss doesn't decrease during training
**A**:
1. Check test script output - did it pass?
2. Make sure labels have target tokens (not all -100)
3. Check learning rate (2e-4 is good)

### Q: CUDA out of memory
**A**: Reduce batch size
```bash
--batch_size 2 --gradient_accumulation_steps 8
```

---

## Documentation

- ðŸ“„ `FIXES_APPLIED_V2.md` - Detailed explanation of fixes
- ðŸ“„ `README.md` - Original pipeline overview
- ðŸ“„ `CHANGES_V2.md` - Android alignment notes

---

## Next Steps After Training

1. âœ… Validate accuracy (should be 85%+)
2. âœ… Merge LoRA weights
3. âœ… Convert to GGUF
4. âœ… Deploy to Android
5. âœ… Test on real images!

---

**Ready? Run the tests and start training! ðŸš€**

```bash
python test_training.py && echo "Tests passed! You're good to go!"
```
